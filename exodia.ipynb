{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Exodia_Supreme_ToSubmit.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f845d7d47ce24e3b9a9d9ec1bff6918b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f7aa7eafa1a24af8829aa5e60d540fd0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7e5594e473f84d038e2197c847c0854d","IPY_MODEL_2eff8ffaa11a4029a54a5cb16b85a9ab"]}},"f7aa7eafa1a24af8829aa5e60d540fd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e5594e473f84d038e2197c847c0854d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b1a6d7d51daf4efca03bc6750a84a2ad","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9f505a0d12e429cbb3f7440723c0b7b"}},"2eff8ffaa11a4029a54a5cb16b85a9ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2944f3e5c1146fa98ef6f60ca5ae2a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 450/450 [04:21&lt;00:00,  1.72it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_164c396a011a41b096113e08f8cdf9ab"}},"b1a6d7d51daf4efca03bc6750a84a2ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b9f505a0d12e429cbb3f7440723c0b7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2944f3e5c1146fa98ef6f60ca5ae2a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"164c396a011a41b096113e08f8cdf9ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn-RfjQUIIkX","executionInfo":{"status":"ok","timestamp":1605820016029,"user_tz":-60,"elapsed":27015,"user":{"displayName":"Manfred Nesti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8t2LgTOU_dvrRZ3GHXtcYzItj0sISoYlKYk31xQ=s64","userId":"02864749125781742556"}},"outputId":"cd4d57db-a665-4a2e-88e3-839fb8a1bb2d"},"source":["# ------------------------------------------------------------------------------\n","# Initial general settings\n","# ------------------------------------------------------------------------------\n","import os\n","import json\n","import pandas as pd\n","from datetime import datetime\n","import time\n","import timeit\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import math\n","from operator import add\n","from scipy.stats import rankdata\n","from tqdm.notebook import tqdm\n","\n","from keras.applications.vgg16 import preprocess_input\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import RMSprop\n","!pip install -U efficientnet\n","import efficientnet.keras as efn\n","from tensorflow.keras import regularizers\n","\n","# KERAS TUNER\n","# !pip install -q -U keras-tuner\n","# import kerastuner as kt\n","# from tensorboard.plugins.hparams import api as hp\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# Set current working directory\n","cwd = '/content/drive/My Drive/Homeworks/ANNDL/HW1'\n","drive.mount('/content/drive')\n","\n","# Set the seed for easy reproducibility\n","SEED = 1337\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting efficientnet\n","  Downloading https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\r\u001b[K     |██████▌                         | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 30.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n","Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n","Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtTfwUYcljuu","executionInfo":{"status":"ok","timestamp":1605820024125,"user_tz":-60,"elapsed":5974,"user":{"displayName":"Manfred Nesti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8t2LgTOU_dvrRZ3GHXtcYzItj0sISoYlKYk31xQ=s64","userId":"02864749125781742556"}},"outputId":"1979dd64-cfb7-4acc-a354-f4ba47e47c67"},"source":["# ------------------------------------------------------------------------------\n","# GPUs monitoring\n","# ------------------------------------------------------------------------------\n","# Set GPU memory growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rqvjEix-ZYN5"},"source":["After trying with hand-crafted CNN, we decide to move to transfer learning, since the preformance is significatively greater. We propose an ensemble method with 5 different strategies (mode, mean, maximum, weighted_mean, weighted_borda) building up 7 different models (m1 - m7). In the following chunck you can choose the models you want to use, if you want to train or load them by previous training sessions and the ensemble strategies you want to use."]},{"cell_type":"code","metadata":{"id":"jB01FZtfUx-v"},"source":["# ------------------------------------------------------------------------------\n","# Model and ensemble methods choosing\n","# ------------------------------------------------------------------------------\n","\n","# Model to use\n","m1 = True\n","m2 = True # ex model 8\n","m3 = True\n","m4 = True\n","m5 = True\n","m6 = True\n","m7 = True\n","\n","# Model to train\n","m1_train = True\n","m2_train = True # ex model 8\n","m3_train = True\n","m4_train = True\n","m5_train = True\n","m6_train = True\n","m7_train = True\n","\n","models = \"m\" + \"1\"*m1 + \"2\"*m2 + \"3\"*m3 + \"4\"*m4 + \"5\"*m5 + \"6\"*m6 + \"7\"*m7\n","\n","# Ensamble to use\n","mode = True\n","mean = True\n","maximum = True\n","weighted_mean = True\n","weighted_borda = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"diZTjZNGaCOb"},"source":["In the following chunck we build the generators, we set the training/validation split (standard 20%) and we make a light image augmentation (seems not too determinant in this task) also introducing some gaussian noise helping to avoid overfitting. With more time, it would make sense to cross-validate in order to make the model wee all the validation data and find an average model.\n","\n","To import the training images we used flow_from_directory after putting every training image in the properly sub-directory using the given JSON file with an easy python script."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGH3KiOZIj2_","executionInfo":{"status":"ok","timestamp":1605820081129,"user_tz":-60,"elapsed":889,"user":{"displayName":"Manfred Nesti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8t2LgTOU_dvrRZ3GHXtcYzItj0sISoYlKYk31xQ=s64","userId":"02864749125781742556"}},"outputId":"2d2bad95-5f50-4ea2-efe2-24eb5f3495b6"},"source":["# ------------------------------------------------------------------------------\n","# Import training set & splitting [training, validation] = [0.8, 0.2]\n","# ------------------------------------------------------------------------------\n","# ImageDataGenerator\n","apply_data_augmentation = True   \n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(\n","                                        rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='constant',\n","                                        cval=0,\n","                                        rescale=1./255,\n","                                        preprocessing_function=None,\n","                                        data_format='channels_last',\n","                                        validation_split=0.2,    \n","                                       )\n","else:\n","    train_data_gen = ImageDataGenerator(\n","    rescale=1./255,                             \n","    validation_split = 0.2)\n","\n","valid_data_gen = ImageDataGenerator(\n","rescale=1./255,                             \n","validation_split = 0.2)\n","\n","# Params\n","bs           = 32\n","num_classes  = 3\n","img_h        = 256\n","img_w        = 256\n","\n","training_dir = os.path.join(cwd, 'training')\n","\n","train_gen = train_data_gen.flow_from_directory(\n","    training_dir,                    \n","    batch_size=bs,\n","    class_mode='categorical',\n","    target_size=(img_h,img_w),\n","    shuffle=True, # it is nice to have them shuffled\n","    seed=SEED,\n","    subset='training')\n","\n","valid_gen = valid_data_gen.flow_from_directory(\n","    training_dir,                    \n","    batch_size=bs,\n","    class_mode='categorical',\n","    target_size=(img_h,img_w),\n","    shuffle=True, # even in validation it is better to let it see diverse data at each epoch\n","    seed=SEED,\n","    subset='validation')\n","\n","train_dataset = tf.data.Dataset.from_generator(\n","    lambda: train_gen,               \n","    output_types=(tf.float32, tf.float32),\n","    output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","train_dataset = train_dataset.repeat()\n","\n","# Gaussian noise to help avoiding overfitting\n","train_dataset = tf.keras.layers.GaussianNoise(0.5)(train_dataset)\n","\n","valid_dataset = tf.data.Dataset.from_generator(\n","    lambda: valid_gen,               \n","    output_types=(tf.float32, tf.float32),\n","    output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 4492 images belonging to 3 classes.\n","Found 1122 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2YL4cGj8azmI"},"source":["We used **Keras tuner** to help us setting the hyperparameters (chunck not in this notebook) but, for simplicity, we also define the **Model_run** function to set on-the-fly some parameters as\n","\n","*   **architecture**: architecture of base model for TL\n","*   **optimizer**: between Adam, RMSprop and Adadelta\n","*   **first_layer**: between an average pooling and a max pooling\n","*   **first_layer_size**: size of first layer\n","*   **dense_size**: size of dense layer\n","*   **dropout_size**: size of dropout\n","*   **L2_reg**: weight of L2 regularization in dense layer to help avoiding overfitting\n","\n"]},{"cell_type":"code","metadata":{"id":"zZI0Dlsut52R"},"source":["# ------------------------------------------------------------------------------\n","# Model run definition\n","# ------------------------------------------------------------------------------\n","def Model_run(architecture, optimizer, first_layer, first_layer_size, dense_size, dropout_size, L2_reg):\n","\n","  # Params\n","  num_classes  = 3\n","  img_h        = 256\n","  img_w        = 256\n","\n","  # Tansfer learning model\n","  if (architecture == \"Xception\"): # Model 1: Xception\n","    base_model = tf.keras.applications.Xception(\n","        input_shape = (img_h, img_w, 3),\n","        include_top = False, weights = 'imagenet') \n","\n","  if (architecture == \"NASNetLarge\"): # Model 2: NASNetLarge\n","    base_model = tf.keras.applications.NASNetLarge(\n","        input_shape = (img_h, img_w, 3),\n","        include_top =  False,\n","        weights = \"imagenet\")\n","    \n","  if (architecture == \"InceptionV3\"): # Model 3: Inception V3 (GoogleNet)\n","    base_model = InceptionV3(input_shape = (img_h, img_w, 3),\n","                             include_top = False,\n","                             weights = 'imagenet')\n"," \n","  if (architecture == \"DenseNet201\"): # Model 4: DenseNet201\n","    base_model = tf.keras.applications.DenseNet201(\n","        include_top = False,\n","        weights = \"imagenet\",\n","        input_shape = (img_h, img_w, 3))\n","  \n","  if (architecture == \"ResNet152V2\"): # Model 5: ResNet 152 V2\n","    base_model = tf.keras.applications.resnet_v2.ResNet152V2(input_shape=(img_h, img_w,3),\n","                                                             include_top=False,\n","                                                             weights=\"imagenet\",\n","                                                             classes = num_classes)\n"," \n","  if (architecture == \"InceptionResNetV2\"): # Model 6: InceptionResNetV2\n","    base_model = tf.keras.applications.InceptionResNetV2(input_shape = (img_h, img_w, 3),\n","                                                         include_top = False,\n","                                                         weights = 'imagenet')\n","\n","  if (architecture == \"ResNet50\"): # Model 7: ResNet50\n","    base_model = ResNet50(input_shape = (img_h, img_w,3),\n","                          include_top = False,\n","                          weights = \"imagenet\")\n","    \n","  if (architecture == \"EfficientNet\"): # Model 8: EfficientNet\n","    base_model = efn.EfficientNetB0(input_shape = (img_h, img_w, 3),\n","                                    include_top = False,\n","                                    weights = 'imagenet')\n","  \n","  # Hand-made NN\n","  if (first_layer == \"AveragePooling2D\"):\n","    x = tf.keras.layers.AveragePooling2D(pool_size=(first_layer_size,first_layer_size))(base_model.output)\n","  if (first_layer == \"MaxPooling2D\"):\n","    x = tf.keras.layers.MaxPooling2D(pool_size=(first_layer_size,first_layer_size))(base_model.output)\n","  \n","  x = tf.keras.layers.Flatten()(x)\t\n","\n","  if (L2_reg > 0):\t\t                 \n","    x = tf.keras.layers.Dense(dense_size, activation='relu', kernel_regularizer=regularizers.l2(L2_reg))(x)\n","  else:\n","    x = tf.keras.layers.Dense(dense_size, activation='relu')(x)\t\t  \n","  \n","  x = tf.keras.layers.Dropout(dropout_size)(x)\t\t\t                             \n","  x = tf.keras.layers.Dense(units=num_classes, activation='softmax')(x)\n","\n","  # Compiler params\n","  if (optimizer == \"Adam\"):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n","  if (optimizer == \"RMSprop\"):\n","    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4)\n","  if (optimizer == \"Adadelta\"): # we found to be a good choice after a lot of trial and error\n","    optimizer = tf.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n","\n","  loss = tf.keras.losses.CategoricalCrossentropy() # easy choice\n","  metrics = [\"accuracy\"]\n","\n","  # Callbacks\n","  # Early stopping callback\n","  ES_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","  # LR adapter callback which help us to get in the right minimum\n","  LR_adapter_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, mode='auto', min_delta=0.0001, cooldown=0)\n","\n","  model = tf.keras.models.Model(base_model.input, x)\n","\n","  model.compile(optimizer = optimizer,\n","                loss = loss,\n","                metrics = metrics)\n","\n","  # model.summary()\n","\n","  model.fit(train_dataset, \n","              epochs           = 150, # normally stops much earlier\n","              steps_per_epoch  = len(train_gen), \n","              validation_data  = valid_dataset,\n","              validation_steps = len(valid_gen),\n","              callbacks        = [ES_callback, LR_adapter_callback])\n","  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3w86K7rrb5Vv"},"source":["After a lot of trial and error we have choosen the following parameters in setting the model structure and training."]},{"cell_type":"code","metadata":{"id":"Rur2c-i8EtGS"},"source":["# ------------------------------------------------------------------------------\n","# Train models\n","# ------------------------------------------------------------------------------\n","if (m1 and m1_train): # Model 1: Xception\n","  print(\"Model 1 training ...\")\n","  model_01 = Model_run(\"Xception\", \"Adadelta\", \"MaxPooling2D\", 7, 512, 0.5, 0.001)\n","  model_01.save(os.path.join(cwd, 'saved_model_01'))\n","  print(\"Model 1 saved\")\n","if (m2 and m2_train): # Model 2: EfficientNet\n","  print(\"Model 2 training ...\")\n","  model_02 = Model_run(\"EfficientNet\", \"Adadelta\", \"AveragePooling2D\", 7, 218, 0.5, 0.001)\n","  model_02.save(os.path.join(cwd, 'saved_model_02'))\n","  print(\"Model 2 saved\")\n","if (m3 and m3_train): # Model 3: Inception V3 (GoogleNet)\n","  print(\"Model 3 training ...\")\n","  model_03 = Model_run(\"InceptionV3\", \"Adadelta\", \"AveragePooling2D\", 5, 218, 0.5, 0.001)\n","  model_03.save(os.path.join(cwd, 'saved_model_03'))\n","  print(\"Model 3 saved\")\n","if (m4 and m4_train): # Model 4: DenseNet201\n","  print(\"Model 4 training ...\")\n","  model_04 = Model_run(\"DenseNet201\", \"Adadelta\", \"AveragePooling2D\", 7, 218, 0.5, 0.001)\n","  model_04.save(os.path.join(cwd, 'saved_model_04'))\n","  print(\"Model 4 saved\")\n","if (m5 and m5_train): # Model 5: ResNet 152 V2\n","  print(\"Model 5 training ...\")\n","  model_05 = Model_run(\"ResNet152V2\", \"Adadelta\", \"AveragePooling2D\", 7, 218, 0.5, 0)\n","  model_05.save(os.path.join(cwd, 'saved_model_05'))\n","  print(\"Model 5 saved\")\n","if (m6 and m6_train): # Model 6: InceptionResNetV2\n","  print(\"Model 6 training ...\")\n","  model_06 = Model_run(\"InceptionResNetV2\", \"Adadelta\", \"MaxPooling2D\", 5, 512, 0.5, 0.001)\n","  model_06.save(os.path.join(cwd, 'saved_model_06'))\n","  print(\"Model 6 saved\")\n","if (m7 and m7_train): # Model 7: ResNet50\n","  print(\"Model 7 training ...\")\n","  model_07 = Model_run(\"ResNet50\", \"Adadelta\", \"AveragePooling2D\", 7, 218, 0.5, 0.001)\n","  model_07.save(os.path.join(cwd, 'saved_model_07'))\n","  print(\"Model 7 saved\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ddf1C9Duf4rN"},"source":["In the following chuck you can load models from previous training session if you have setted\n","\n","```\n","mx = True\n","mx_train = False\n","```\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wu2UF9WVtXV","executionInfo":{"status":"ok","timestamp":1605820514186,"user_tz":-60,"elapsed":432807,"user":{"displayName":"Manfred Nesti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8t2LgTOU_dvrRZ3GHXtcYzItj0sISoYlKYk31xQ=s64","userId":"02864749125781742556"}},"outputId":"e3246ffd-1453-44d1-fd7b-24fc9ebad061"},"source":["# ------------------------------------------------------------------------------\n","# Load models\n","# ------------------------------------------------------------------------------\n","if (m1 and not m1_train): # Model 1: Xception\n","  print(\"Model 01 loading ...\")\n","  model_01 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_01'))\n","  print(\"Model 01 loaded\")\n","if (m2 and not m2_train): # Model 2: NASNetLarge\n","  print(\"Model 02 loading ...\")\n","  model_02 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_02'))\n","  print(\"Model 02 loaded\")\n","if (m3 and not m3_train): # Model 3: Inception V3 (GoogleNet)\n","  print(\"Model 03 loading ...\")\n","  model_03 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_03'))\n","  print(\"Model 03 loaded\")\n","if (m4 and not m4_train): # Model 4: DenseNet201\n","  print(\"Model 04 loading ...\")\n","  model_04 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_04'))\n","  print(\"Model 04 loaded\")\n","if (m5 and not m5_train): # Model 5: ResNet 152 V2\n","  print(\"Model 05 loading ...\")\n","  model_05 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_05'))\n","  print(\"Model 05 loaded\")\n","if (m6 and not m6_train): # Model 6: InceptionResNetV2\n","  print(\"Model 06 loading ...\")\n","  model_06 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_06'))\n","  print(\"Model 06 loaded\")\n","if (m7 and not m7_train): # Model 7: ResNet50\n","  print(\"Model 07 loading ...\")\n","  model_07 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_07'))\n","  print(\"Model 07 loaded\")\n","if (m8 and not m8_train): # Model 8: EfficientNet\n","  print(\"Model 08 loading ...\")\n","  model_08 = tf.keras.models.load_model(os.path.join(cwd, 'saved_model_08'))\n","  print(\"Model 08 loaded\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model 01 loading ...\n","Model 01 loaded\n","Model 03 loading ...\n","Model 03 loaded\n","Model 04 loading ...\n","Model 04 loaded\n","Model 05 loading ...\n","Model 05 loaded\n","Model 06 loading ...\n","Model 06 loaded\n","Model 07 loading ...\n","Model 07 loaded\n","Model 08 loading ...\n","Model 08 loaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NrQxcN3agR1s"},"source":["We make prediction, as well as with single models,  also on the following ensemble methods\n","\n","\n","*   **mode**: for each test image we take the majority of votes given by the 7 models\n","*   **mean**: for each test image we sum up the probabilities given by the 7 models and we take the class with highest probability\n","*   **maximum**: for each test image we take all the probabilities given by the 7 models and we take the maximum one\n","*   **weighted_mean**: as mean but every model is weighted based on its validation accuracy\n","*   **weighted_Borda**: as mean but every model previously gives its vote as a number between 1 and class_number based on its probabilities (Borda voting method), also weighted on its validation accuracy\n","\n","Ensemble method is useful for unstable models that are different one from other and specialized on catch different features in images. In our case we always have obtained better results with ensemble method, despite, probably, our models are quite similar.\n","\n","We found **weighted_mean** (95.1 % on test set) to be the best ensemble methods, taking into account exactly the single probabililties given by each model."]},{"cell_type":"code","metadata":{"id":"zjSdpvV4bJwd","colab":{"base_uri":"https://localhost:8080/","height":375,"referenced_widgets":["f845d7d47ce24e3b9a9d9ec1bff6918b","f7aa7eafa1a24af8829aa5e60d540fd0","7e5594e473f84d038e2197c847c0854d","2eff8ffaa11a4029a54a5cb16b85a9ab","b1a6d7d51daf4efca03bc6750a84a2ad","b9f505a0d12e429cbb3f7440723c0b7b","f2944f3e5c1146fa98ef6f60ca5ae2a2","164c396a011a41b096113e08f8cdf9ab"]},"executionInfo":{"status":"ok","timestamp":1605821082350,"user_tz":-60,"elapsed":1000676,"user":{"displayName":"Manfred Nesti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8t2LgTOU_dvrRZ3GHXtcYzItj0sISoYlKYk31xQ=s64","userId":"02864749125781742556"}},"outputId":"7a2d0056-9691-4d82-dd12-9930d97bcbbe"},"source":["# ------------------------------------------------------------------------------\n","# Prediction and saving results\n","# ------------------------------------------------------------------------------\n","# Function create_csv definition\n","\n","def create_csv(results, models, ensemble, results_dir=cwd):\n","    if not os.path.exists(results_dir):\n","      os.mkdir(results_dir)\n","    csv_filename = 'results_' + datetime.now().strftime('%b%d_%H-%M-%S') + \"_\" + models + \"_\" + ensemble + '.csv'\n","    with open(os.path.join(results_dir, csv_filename), 'w') as f:\n","        f.write('Id,Category\\n')\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')\n","    return csv_filename\n","\n","image_filenames = next(os.walk(os.path.join(cwd, 'test')))[2]\n","\n","# Validation accuracies\n","if (m1):\n","  print(\"Model 1 validation accuracy:\")\n","  val_acc_01 = model_01.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m2):\n","  print(\"Model 2 validation accuracy:\")\n","  val_acc_02 = model_02.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m3):\n","  print(\"Model 3 validation accuracy:\")\n","  val_acc_03 = model_03.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m4):\n","  print(\"Model 4 validation accuracy:\")\n","  val_acc_04 = model_04.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m5):\n","  print(\"Model 5 validation accuracy:\")\n","  val_acc_05 = model_05.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m6):\n","  print(\"Model 6 validation accuracy:\")\n","  val_acc_06 = model_06.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","if (m7):\n","  print(\"Model 7 validation accuracy:\")\n","  val_acc_07 = model_07.evaluate(valid_dataset,steps=len(valid_gen),verbose=1)[1]\n","\n","# Initialize results ensemble methods\n","if (maximum):\n","  results_maximum = {}\n","if (mean):\n","  results_mean = {}\n","if (mode):\n","  results_mode = {}\n","if (weighted_mean):\n","  results_weighted_mean = {}\n","if (weighted_borda):\n","  results_weighted_borda = {}\n","\n","# Computed validation accuracy for weighted_mean\n","if (m1):\n","  results_m1 = {}\n","if (m2):\n","  results_m2 = {}\n","if (m3):\n","  results_m3 = {}\n","if (m4):\n","  results_m4 = {}\n","if (m5):\n","  results_m5 = {}\n","if (m6):\n","  results_m6 = {}\n","if (m7):\n","  results_m7 = {}\n","\n","for image_name in tqdm(image_filenames):\n","  img = Image.open(os.path.join(cwd, 'test', image_name)).convert('RGB')\n","  img = img.resize((img_h,img_w))\n","  img_array = np.array(img)\n","  img_array = np.expand_dims(img_array, 0) \n","\n","  # Predictions probabilities for current img\n","  if (m1):\n","    pred_01 = model_01.predict(x=img_array/255.)\n","    results_m1[image_name] = np.argmax(pred_01)\n","  if (m2):\n","    pred_02 = model_02.predict(x=img_array/255.)\n","    results_m2[image_name] = np.argmax(pred_02)\n","  if (m3):\n","    pred_03 = model_03.predict(x=img_array/255.)\n","    results_m3[image_name] = np.argmax(pred_03)\n","  if (m4):\n","    pred_04 = model_04.predict(x=img_array/255.)\n","    results_m4[image_name] = np.argmax(pred_04)\n","  if (m5):\n","    pred_05 = model_05.predict(x=img_array/255.)\n","    results_m5[image_name] = np.argmax(pred_05)\n","  if (m6):\n","    pred_06 = model_06.predict(x=img_array/255.)\n","    results_m6[image_name] = np.argmax(pred_06)\n","  if (m7):\n","    pred_07 = model_07.predict(x=img_array/255.)\n","    results_m7[image_name] = np.argmax(pred_07)\n","  \n","  if (maximum):\n","    # ----------------------------------------------------------------------------\n","    # Maximum of choosen models\n","    # ----------------------------------------------------------------------------\n","    # Dictionary {model_number : max_probabily}\n","    max_val = {}\n","    \n","    if (m1):\n","      max_val[1] = np.max(pred_01)\n","    if (m2):\n","      max_val[2] = np.max(pred_02)\n","    if (m3):\n","      max_val[3] = np.max(pred_03)\n","    if (m4):\n","      max_val[4] = np.max(pred_04)\n","    if (m5):\n","      max_val[5] = np.max(pred_05)\n","    if (m6):\n","      max_val[6] = np.max(pred_06)\n","    if (m7):\n","      max_val[7] = np.max(pred_07)\n","    \n","    # Model with highest max_probability\n","    best = max(max_val, key=max_val.get)\n","\n","    # Classification of best model\n","    if (best == 1):\n","      prediction_maximum = np.argmax(pred_01)\n","    elif (best == 2):\n","      prediction_maximum = np.argmax(pred_02)\n","    elif (best == 3):\n","      prediction_maximum = np.argmax(pred_03)\n","    elif (best == 4):\n","      prediction_maximum = np.argmax(pred_04)\n","    elif (best == 5):\n","      prediction_maximum = np.argmax(pred_05)\n","    elif (best == 6):\n","      prediction_maximum = np.argmax(pred_06)\n","    else:\n","      prediction_maximum = np.argmax(pred_07)\n","\n","    results_maximum[image_name] = prediction_maximum\n","\n","  if (mean):\n","    # ----------------------------------------------------------------------------\n","    # Mean of choosen models\n","    # ----------------------------------------------------------------------------\n","    # Sum of predictions of each model (NOT normalized)\n","    pred_sum = [0, 0, 0]\n","    \n","    if (m1):\n","      pred_sum = list(map(add, pred_sum, pred_01))\n","    if (m2):\n","      pred_sum = list(map(add, pred_sum, pred_02))\n","    if (m3):\n","      pred_sum = list(map(add, pred_sum, pred_03))\n","    if (m4):\n","      pred_sum = list(map(add, pred_sum, pred_04))\n","    if (m5):\n","      pred_sum = list(map(add, pred_sum, pred_05))\n","    if (m6):\n","      pred_sum = list(map(add, pred_sum, pred_06))\n","    if (m7):\n","      pred_sum = list(map(add, pred_sum, pred_07))\n","\n","    # Class with highest sum of probability\n","    prediction_mean = np.argmax(pred_sum)\n","    results_mean[image_name] = prediction_mean\n","\n","  if (mode):\n","    # ----------------------------------------------------------------------------\n","    # Mode of choosen models\n","    # ----------------------------------------------------------------------------\n","    # List of all probability lists\n","    pred_list = []\n","    \n","    if (m1):\n","      pred_list = [pred_list, pred_01]\n","    if (m2):\n","      pred_list = [pred_list, pred_02]\n","    if (m3):\n","      pred_list = [pred_list, pred_03]\n","    if (m4):\n","      pred_list = [pred_list, pred_04]\n","    if (m5):\n","      pred_list = [pred_list, pred_05]\n","    if (m6):\n","      pred_list = [pred_list, pred_06]\n","    if (m7):\n","      pred_list = [pred_list, pred_07]\n","\n","    pred_list = pred_list[1:] # removes first empty list\n","\n","    # Counter of votes for each class\n","    pred = [0, 0, 0]\n","    for elem in pred_list:\n","      pred[np.argmax(elem)] += 1\n","\n","    results_mode[image_name]  = np.argmax(pred)\n","\n","  if (weighted_mean):\n","    # ----------------------------------------------------------------------------\n","    # Weighted mean of choosen models\n","    # ----------------------------------------------------------------------------\n","    # Sum of predictions of each model (NOT normalized)\n","    pred_sum_weighted_mean = [0, 0, 0]\n","    \n","    if (m1):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_01*val_acc_01))\n","    if (m2):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_02*val_acc_02))\n","    if (m3):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_03*val_acc_03))\n","    if (m4):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_04*val_acc_04))\n","    if (m5):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_05*val_acc_05))\n","    if (m6):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_06*val_acc_06))\n","    if (m7):\n","      pred_sum_weighted_mean = list(map(add, pred_sum_weighted_mean, pred_07*val_acc_07))\n","\n","    # Class with highest sum of probability\n","    results_weighted_mean[image_name] = np.argmax(pred_sum_weighted_mean)\n","\n","  if (weighted_borda):\n","    # ----------------------------------------------------------------------------\n","    # Weighted Borda method applied to choosen models\n","    # ----------------------------------------------------------------------------\n","    # Sum of predictions of each model (NOT normalized)\n","    pred_sum_weighted_borda = [0, 0, 0]\n","\n","    if (m1):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_01), val_acc_01)))\n","    if (m2):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_02), val_acc_02)))\n","    if (m3):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_03), val_acc_03)))\n","    if (m4):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_04), val_acc_04)))\n","    if (m5):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_05), val_acc_05)))\n","    if (m6):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_06), val_acc_06)))\n","    if (m7):\n","      pred_sum_weighted_borda = list(map(add, pred_sum_weighted_borda, np.inner(rankdata(pred_07), val_acc_07)))\n","\n","    # Class with highest sum of probability\n","    results_weighted_borda[image_name] = np.argmax(list(pred_sum_weighted_borda))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model 1 validation accuracy:\n","36/36 [==============================] - 191s 5s/step - loss: 0.3224 - accuracy: 0.9144\n","Model 3 validation accuracy:\n","36/36 [==============================] - 11s 317ms/step - loss: 0.3408 - accuracy: 0.9127\n","Model 4 validation accuracy:\n","36/36 [==============================] - 15s 408ms/step - loss: 0.2935 - accuracy: 0.9385\n","Model 5 validation accuracy:\n","36/36 [==============================] - 17s 485ms/step - loss: 0.2552 - accuracy: 0.9127\n","Model 6 validation accuracy:\n","36/36 [==============================] - 15s 427ms/step - loss: 0.3683 - accuracy: 0.9153\n","Model 7 validation accuracy:\n","36/36 [==============================] - 12s 338ms/step - loss: 0.3305 - accuracy: 0.9064\n","Model 8 validation accuracy:\n","36/36 [==============================] - 11s 302ms/step - loss: 0.4140 - accuracy: 0.8957\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f845d7d47ce24e3b9a9d9ec1bff6918b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=450.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5edfc12ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5ede9a28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5ede148ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W_HVKTM5iAgc"},"source":["In this last chunck we create csv files, named with timestamp, models envolved and ensamble method choosen."]},{"cell_type":"code","metadata":{"id":"mj7KNEL_EwFj"},"source":["# ------------------------------------------------------------------------------\n","# Create csv\n","# ------------------------------------------------------------------------------\n","# Create csv for single models\n","if (m1):\n","  csv_filename_m1 = create_csv(results_m1, \"m1\", \"single\", os.path.join(cwd, 'results'))\n","if (m2):\n","  csv_filename_m2 = create_csv(results_m2, \"m2\", \"single\", os.path.join(cwd, 'results'))\n","if (m3):\n","  csv_filename_m3 = create_csv(results_m3, \"m3\", \"single\", os.path.join(cwd, 'results'))\n","if (m4):\n","  csv_filename_m4 = create_csv(results_m4, \"m4\", \"single\", os.path.join(cwd, 'results'))\n","if (m5):\n","  csv_filename_m5 = create_csv(results_m5, \"m5\", \"single\", os.path.join(cwd, 'results'))\n","if (m6):\n","  csv_filename_m6 = create_csv(results_m6, \"m6\", \"single\", os.path.join(cwd, 'results'))\n","if (m7):\n","  csv_filename_m7 = create_csv(results_m7, \"m7\", \"single\", os.path.join(cwd, 'results'))\n","if (m8):\n","  csv_filename_m8 = create_csv(results_m8, \"m8\", \"single\", os.path.join(cwd, 'results'))\n","\n","# Create csv for ensemble methods\n","if (maximum):\n","  csv_filename_maximum = create_csv(results_maximum, models, \"maximum\", os.path.join(cwd, 'results'))\n","if (mean):\n","  csv_filename_mean = create_csv(results_mean, models, \"mean\", os.path.join(cwd, 'results'))\n","if (mode):\n","  csv_filename_mode = create_csv(results_mode, models, \"mode\", os.path.join(cwd, 'results'))\n","if (weighted_mean):\n","  csv_filename_weighted_mean = create_csv(results_weighted_mean, models, \"weighted_mean\", os.path.join(cwd, 'results'))\n","if (weighted_borda):\n","  csv_filename_weighted_borda = create_csv(results_weighted_borda, models, \"weighted_borda\", os.path.join(cwd, 'results'))"],"execution_count":null,"outputs":[]}]}